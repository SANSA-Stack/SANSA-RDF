{
  "paragraphs": [
    {
      "text": "%spark\nimport org.apache.jena.riot.Lang\nimport com.typesafe.config.ConfigFactory\nimport net.sansa_stack.ml.spark.clustering.utils.DataProcessing\nimport net.sansa_stack.rdf.spark.io._\n\n\nval input \u003d \"hdfs://namenode:8020/data/niedersachsen-pois_osm_rdf5L.nt\"\nval lang \u003d Lang.NTRIPLES\n\nval triples \u003d spark.rdf(lang)(input)\n\ntriples.take(10).foreach(println)",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:06:36.491",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312766859_630373974",
      "id": "paragraph_1610312766859_630373974",
      "dateCreated": "2021-01-10 21:06:06.859",
      "status": "READY"
    },
    {
      "text": "%spark\nimport org.apache.spark.rdd.RDD\ncase class spatial(longitude: Double, latitude: Double)\ndef getPOICoordinates: RDD[(Long, spatial)] \u003d {\n    // get the coordinates of pois\n    val pattern \u003d \"POINT (.+ .+)\".r\n    val poiCoordinatesString \u003d triples.filter(x \u003d\u003e x.getPredicate.toString().equalsIgnoreCase(\"http://www.opengis.net/ont/geosparql#asWKT\"))\n    val removeOther\u003dpoiCoordinatesString.filter(f \u003d\u003e (!f.getSubject.toString().contains(\"http://openstreetmap.org/way/\")))\n    val removeRelation\u003dremoveOther.filter(f \u003d\u003e (!f.getSubject.toString().contains(\"http://openstreetmap.org/relation/\")))\n      .map(x \u003d\u003e (x.getSubject.toString().replace(\"http://openstreetmap.org/node/\", \"\").replace(\"/geom\", \"\").toLong,\n        pattern.findFirstIn(x.getObject.toString()).head.replace(\"POINT \", \"\")\n          .replace(\"^^http://www.opengis.net/ont/geosparql#wktLiteral\", \"\").replaceAll(\"^\\\"|\\\"$\", \"\"))) \n          // transform to Coordinate object\n    val m\u003dremoveRelation.mapValues(x \u003d\u003e {\n        val coordinates \u003d x.replace(\"(\", \"\").replace(\")\", \"\").split(\" \")\n        spatial(coordinates(0).toDouble, coordinates(1).toDouble)\n    })\n    m\n }\n\ndef getCat(): RDD[(Long, String)] \u003d {\n    val keyName\u003dtriples.filter(f\u003d\u003ef.getPredicate.toString().contains(\"https://wiki.openstreetmap.org/Key:amenity\"))\n    val filterSub\u003dkeyName.filter(f\u003d\u003ef.getSubject.toString().contains(\"http://openstreetmap.org/node\"))\n    val getKV\u003d filterSub.map(x \u003d\u003e ((x.getSubject.toString().replace(\"http://openstreetmap.org/node/\", \"\").toLong),\n        x.getObject.toString()))\n    getKV.take(2).foreach(println)\n    getKV    \n}\n",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:06:48.551",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312804171_1104262456",
      "id": "paragraph_1610312804171_1104262456",
      "dateCreated": "2021-01-10 21:06:44.171",
      "status": "READY"
    },
    {
      "text": "%spark\n//case class spatial(longitude: Double, latitude: Double)\ncase class PoiOSM(poi_id: Long, coordinate: spatial, categories: String)\n var poiCoordinates: RDD[(Long, spatial)]\u003d getPOICoordinates.persist()\n  var categoriesOSM\u003d getCat\n  var join\u003dpoiCoordinates.join(categoriesOSM)//.join(cuisne)\n  val pois\u003djoin.map(f\u003d\u003ePoiOSM(f._1,f._2._1,f._2._2.toString))",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:07:09.928",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312808638_581623683",
      "id": "paragraph_1610312808638_581623683",
      "dateCreated": "2021-01-10 21:06:48.639",
      "status": "READY"
    },
    {
      "text": "%spark\n//case class PoiOSM(poi_id: Long, coordinate: spatial, categories: String)\ncase class ClusterOSM(cluster_id: Int, poi_in_cluster: Array[PoiOSM])\ncase class ClsutersOSM(numOfClusters: Int,clusterSizes: Array[Int],clusters:Array[ClusterOSM])\nval poiCategorySetVienna \u003d pois.map(poi \u003d\u003e (poi.categories,(poi.coordinate,poi.poi_id))).persist()\nval a\u003dpoiCategorySetVienna.groupByKey()\nval b\u003da.zipWithIndex()\nval forJSON\u003db.map(f \u003d\u003e (f._2,(f._1._1,f._1._2.toArray)))\nval t\u003dforJSON.map(f \u003d\u003e ClusterOSM(f._1.toInt,f._2._2.map(g \u003d\u003e PoiOSM(g._2,g._1,f._2._1)))).collect()\nval assignments \u003d forJSON.collect().toList.map(f \u003d\u003e f._2._2.length).toArray\nval assm\u003dassignments.toArray\nval lenthCluster\u003dassm.length\nval finaloutputforsaving\u003d ClsutersOSM(lenthCluster,assm,t)",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:07:27.222",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312831854_1480224689",
      "id": "paragraph_1610312831854_1480224689",
      "dateCreated": "2021-01-10 21:07:11.854",
      "status": "READY"
    },
    {
      "text": "%spark\nz.angularBind(\"clustersPois\", finaloutputforsaving)",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:07:46.879",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312850537_1358829050",
      "id": "paragraph_1610312850537_1358829050",
      "dateCreated": "2021-01-10 21:07:30.538",
      "status": "READY"
    },
    {
      "text": "%spark\nval c\u003db.map(f\u003d\u003e((f._2,f._1._1,f._1._2)))\nval d\u003db.map(f\u003d\u003ef._1._2.map(g\u003d\u003e(f._2,f._1._1,g._1,g._2)).toList)",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:07:58.971",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312873228_1285244557",
      "id": "paragraph_1610312873228_1285244557",
      "dateCreated": "2021-01-10 21:07:53.228",
      "status": "READY"
    },
    {
      "text": "%spark\nimport com.vividsolutions.jts.geom.{ Coordinate, Envelope, GeometryFactory, Point }\n   \nval geometryFactory \u003d new GeometryFactory()\nval dbparam\u003dd.collect.map(f \u003d\u003e f.map{g \u003d\u003e\n    val clsuterid\u003dg._1+\".\"\n    val poid\u003dg._4\n    val combineId\u003dclsuterid+poid\n    val lat\u003dg._3.latitude\n    val long\u003dg._3.longitude\n    val point \u003d geometryFactory.createPoint(new Coordinate(long, lat))\n        point.setUserData(combineId)\n        point\n    })\ndbparam.take(3).foreach(println)\n",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:08:10.982",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312886228_1804343642",
      "id": "paragraph_1610312886228_1804343642",
      "dateCreated": "2021-01-10 21:08:06.228",
      "status": "READY"
    },
    {
      "text": "%spark\nimport net.sansa_stack.ml.spark.clustering.algorithms.DBSCAN\nimport net.sansa_stack.ml.spark.clustering._\nimport scala.util.parsing.json._\nimport org.json4s.jackson.Serialization.write\nimport org.json4s._\nimport org.json4s.jackson.JsonMethods._\nimport com.vividsolutions.jts.geom.{ Coordinate, Envelope, GeometryFactory, Point }   \n\nval dbfilter\u003ddbparam.filter(f \u003d\u003e f.size \u003e 35) // NOTE: 35 takes time but if reduced it may raise a GeoSpark paritioning issue\ncase class Coordinate2(longitude: Double, latitude: Double)\ncase class Cluster2(cluster_id: String, cluster_id_kmeans:String,poi_in_cluster:  Array[Coordinate2])\ncase class Clusters1(numOfClusters: Int, clusterSizes:Array[Int], clusters: Array[Cluster2])\n    \nval broadcastRDD \u003d spark.sparkContext.broadcast(dbfilter)\n\nval convertRDD\u003dbroadcastRDD.value.map{case u \u003d\u003e spark.sparkContext.parallelize(u)}\n\nval dbscan \u003d triples.cluster(ClusteringAlgorithm.DBSCAN).asInstanceOf[DBSCAN]\n\nval k \u003d convertRDD.map(f \u003d\u003e dbscan.dbclusters(f, 0.01, 2, spark))\n    \nval clusterIDPOIidPair \u003d k.map(arr \u003d\u003e arr.map(f \u003d\u003e (f._1, f._2.map(g \u003d\u003e (g._1,g._2.lat,g._2.lon)))).groupByKey())\nval temp\u003d clusterIDPOIidPair.reduce( _ ++ _ ).repartition(5)\n\n \nval col\u003dtemp.collect().toArray\nval exp\u003dcol.map(f\u003d\u003e(f._1,f._2.map(f \u003d\u003e (f.length)).toArray)).toArray\n     \ndef subsequenceT(a:String):String \u003d {\na.substring(0,  a.indexOf(\".\"))\n\n}\n\ndef findTerm(gt: (String, Iterable[Array[(String, Double, Double)]])): Cluster2 \u003d {\n    val a\u003dgt._1\n    val c\u003dgt._2.map(f \u003d\u003e f.head).map(f \u003d\u003e f._1).head\n    val func\u003dsubsequenceT(c)\n    val b\u003dgt._2.flatMap(f \u003d\u003e f.map(f \u003d\u003e (Coordinate2(f._3,f._2))))\n    (Cluster2(a,func,b.toArray))\n}\n\nval newdata\u003dcol.map(f \u003d\u003e f._2.map(f \u003d\u003e f.length).toArray).flatMap(f \u003d\u003e f).toArray\nval poisDB\u003dClusters1(exp.size, newdata,col.map(g \u003d\u003e findTerm(g)))\n",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:08:46.513",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312891076_158345542",
      "id": "paragraph_1610312891076_158345542",
      "dateCreated": "2021-01-10 21:08:11.076",
      "status": "READY"
    },
    {
      "text": "%spark\nz.angularBind(\"someScopeVar\", poisDB)",
      "user": "anonymous",
      "dateUpdated": "2021-01-10 21:09:06.363",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1610312932160_933907653",
      "id": "paragraph_1610312932160_933907653",
      "dateCreated": "2021-01-10 21:08:52.160",
      "status": "READY"
    }
  ],
  "name": "POI Geo-clustering",
  "id": "2FU8Z45MA",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0-preview2",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}